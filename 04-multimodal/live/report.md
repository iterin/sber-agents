# Отчёт о выполнении задания: Персональный финансовый советник

## Название проекта и краткое описание

**Персональный финансовый советник** — это Telegram-бот для автоматизированного учёта доходов и расходов. Бот анализирует текстовые сообщения, изображения чеков и голосовые сообщения пользователя, автоматически извлекает финансовые транзакции и ведёт учёт баланса.

Проект реализован как монолитное Python-приложение с использованием современных AI-технологий для обработки мультимодального контента.

## Вариант задания

**Расширенный вариант** — реализация полного функционала включая:
- Обработку текстовых сообщений
- Обработку изображений чеков
- Локальную транскрибацию голосовых сообщений
- Интеграцию с внешними LLM провайдерами
- Локальное развертывание моделей через Ollama

## Реализованные возможности

- [x] **Обработка текстовых сообщений** — извлечение транзакций из текста через structured output
- [x] **Обработка изображений** — распознавание чеков и скриншотов через Vision API
- [x] **Локальная транскрибация голосовых сообщений** — конвертация речи в текст через Vosk (русский язык, CPU)
- [x] **Ведение учёта транзакций** — хранение доходов/расходов в памяти с категоризацией
- [x] **Формирование отчётов** — баланс, статистика по категориям, список всех транзакций
- [x] **История диалога** — поддержка контекста для ответов на вопросы
- [x] **Поддержка нескольких LLM провайдеров** — OpenRouter, Ollama
- [x] **Локальное развертывание** — возможность работы без интернета
- [x] **Асинхронная архитектура** — одновременная обработка нескольких пользователей

## Технологический стек

### Основные технологии
- **Python 3.11+** — основной язык разработки
- **uv** — менеджер зависимостей и виртуального окружения
- **aiogram 3.x** — асинхронный фреймворк для Telegram Bot API
- **openai** — единый клиент для работы с LLM через OpenRouter/Ollama
- **pydantic** — валидация данных и structured output для LLM
- **Vosk** — локальная транскрибация речи на CPU
- **soundfile + ffmpeg-python** — обработка аудио файлов
- **python-dotenv** — управление конфигурацией через переменные окружения

### Модели AI
- **Текстовые сообщения**: `llama3.2`, `openai/gpt-oss-20b:free`
- **Обработка изображений**: `llama3.2-vision`, `meta-llama/llama-3.2-11b-vision-instruct`
- **Транскрибация речи**: `vosk-model-small-ru-0.22` (русский язык)

## Инструменты AI-driven разработки

### IDE и инструменты
- **Cursor** — основная среда разработки с поддержкой AI-ассистента
- **GitHub Copilot** — AI-помощник для автодополнения кода
- **Claude 3.5 Sonnet** — LLM для генерации кода, рефакторинга и решения задач
- **Grok** — AI-ассистент для анализа кода и отладки

### AI-модели в разработке
- **Claude 3.5 Sonnet** — основной инструмент для написания кода, анализа требований, генерации документации
- **GPT-4** — использовался для анализа ошибок и оптимизации промптов
- **Llama 3.2** — тестирование функционала на локальных моделях

## Скриншоты работы

### Основной интерфейс и команды
![Главное меню бота](screenshots/bot_start.png)
*Приветственное сообщение и команды бота*

### Обработка текстовых сообщений
![Извлечение транзакций из текста](screenshots/text_transaction.png)
*Автоматическое извлечение транзакции из текстового сообщения*

### Обработка изображений чеков
![Распознавание чека](screenshots/image_processing.png)
*Обработка изображения чека с извлечением позиций*

### Локальная транскрибация голоса
![Транскрибация голосового сообщения](screenshots/voice_transcription.png)
*Конвертация голосового сообщения в текст через Vosk*

### Отчёты о балансе
![Отчёт о финансовом балансе](screenshots/balance_report.png)
*Подробный отчёт с балансом и статистикой по категориям*

## Облачный сервер

### Конфигурация сервера
- **Провайдер**: Immers.cloud
- **IP-адрес**: 195.209.210.141
- **Операционная система**: Ubuntu 22.04
- **GPU**: NVIDIA (проверено наличие драйверов)
- **Модели Ollama**: `qwen2.5:7b-instruct`, `llama3.2:1b`

### Развертывание
- Настроено защищённое SSH-подключение через ключ `~/.ssh/immers-vm.pem`
- Установлен Ollama с моделями для локальной работы
- Настроен доступ к Ollama через интернет (порт 22 открыт, порт 11434 закрыт для безопасности)
- Создано виртуальное окружение для Python зависимостей

## Основные вызовы и решения

### 1. Мультимодальная обработка через OpenAI совместимый API
**Вызов**: Ollama не поддерживает vision API в OpenAI-compatible endpoint `/v1/chat/completions`.

**Решение**: Переключились на нативный Ollama API `/api/generate` для изображений, сохранив OpenAI клиент для текстовых сообщений.

### 2. Скачивание моделей для транскрибации
**Вызов**: `faster-whisper` требовал скачивания больших моделей (~1-2GB) и имел проблемы с загрузкой.

**Решение**: Заменили на `Vosk` с компактной русской моделью (~50MB), которая работает на CPU и не требует интернета.

### 3. Конвертация аудио форматов
**Вызов**: Telegram отправляет голосовые сообщения в формате OGG/Opus, а Vosk требует WAV 16kHz mono.

**Решение**: Интегрировали `ffmpeg` для автоматической конвертации с помощью `ffmpeg-python`.

### 4. Structured output в разных LLM
**Вызов**: Разные модели (OpenRouter vs Ollama) по-разному обрабатывают JSON schema.

**Решение**: Реализовали гибкий парсинг JSON с fallback на regex для извлечения structured данных из ответов LLM.

### 5. Управление зависимостями в разных окружениях
**Вызов**: Конфликты версий пакетов между системным Python и виртуальным окружением.

**Решение**: Перешли на `uv` для изолированного управления зависимостями и автоматического разрешения конфликтов.

## Что узнал нового

### 1. Работа с мультимодальными LLM
Узнал о различиях между Vision API разных провайдеров и особенностях интеграции изображений в промпты. Понял важность structured output для надёжного извлечения данных из LLM ответов.

### 2. Локальные решения для AI
Освоил работу с локальными моделями через Ollama и понял преимущества/недостатки локального vs облачного подхода. Научился настраивать GPU-серверы для AI задач.

### 3. Асинхронное программирование в Python
Глубже разобрался в asyncio, научился правильно организовывать асинхронные операции с файлами, сетевыми запросами и внешними процессами (ffmpeg).

### 4. Интеграция speech-to-text
Изучил различные подходы к транскрибации речи: облачные API (Whisper), локальные решения (Vosk, faster-whisper) и научился выбирать оптимальный вариант под конкретные требования.

### 5. AI-driven разработка
Освоил работу с AI-ассистентами в IDE, научился эффективно использовать LLM для генерации кода, отладки и анализа требований проекта.

---

## Заключение

Проект успешно реализован с использованием современных AI-технологий и лучших практик Python-разработки. Бот демонстрирует полную функциональность для персонального финансового учёта с поддержкой мультимодального ввода. Архитектура позволяет легко расширять функционал и адаптировать под новые требования.

**Статус**: ✅ Готов к использованию
