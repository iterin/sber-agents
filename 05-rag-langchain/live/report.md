# Отчет о выполнении задания: RAG-ассистент Сбербанка

## Название проекта и краткое описание

**RAG-ассистент Сбербанка** - Telegram-бот с системой Retrieval-Augmented Generation (RAG) для ответов на вопросы по документам Сбербанка. Бот автоматически индексирует PDF документы и JSON датасет с вопросами-ответами, позволяя пользователям получать точные ответы на основе реальных банковских документов.

## Вариант задания

**Базовый вариант** - реализация RAG-ассистента с поддержкой PDF документов и базовым функционалом Telegram-бота.

## Реализованные возможности

- [x] **RAG на базе LangChain** - ответы на основе реальных документов
- [x] **Индексация PDF документов** - автоматическая обработка при старте
- [x] **Поддержка JSON датасета** - загрузка вопросов-ответов из JSON файла
- [x] **Telegram Bot API** - полный функционал бота с командами
- [x] **Контекстный диалог** - поддержка истории сообщений
- [x] **Асинхронная обработка** - одновременная работа с множеством пользователей
- [x] **Логирование** - запись всех событий в файл для отладки
- [x] **Query Transformation** - улучшение поисковых запросов (отключено для точности)
- [x] **Оригинальный retrieval** - использование оригинального вопроса для поиска
- [x] **Отладка RAG** - полная логика анализа retrieval и generation

## Технологический стек

- **Python 3.11+** - основной язык разработки
- **uv** - менеджер зависимостей и виртуального окружения
- **aiogram 3.x** - фреймворк для Telegram Bot API
- **LangChain** - фреймворк для RAG-приложений
- **langchain-openai** - интеграция с OpenAI-совместимыми API
- **PyPDF** - загрузка и парсинг PDF-документов
- **jq** - обработка JSON файлов (для JSONLoader)
- **python-dotenv** - работа с переменными окружения
- **Make** - автоматизация запуска и управления

## Используемые модели

- **LLM для генерации ответов**: `accounts/fireworks/models/gpt-oss-120b` (Fireworks)
- **LLM для query transformation**: `accounts/fireworks/models/gpt-oss-120b` (Fireworks)
- **Модель эмбеддингов**: `accounts/fireworks/models/qwen3-embedding-8b` (Fireworks)

## Эксперименты с индексацией

### Описание экспериментов с разными размерами чанков

В процессе разработки были протестированы различные параметры индексации для оптимизации качества поиска и генерации ответов:

#### Эксперимент 1: Размеры чанков
- **chunk_size=500, chunk_overlap=50** (исходные настройки)
- **chunk_size=800, chunk_overlap=100** (увеличенные для банковских документов)
- **chunk_size=600, chunk_overlap=80** (компромиссный вариант)

#### Эксперимент 2: Параметры retrieval
- **k=3** (минимальный поиск)
- **k=7** (увеличенный поиск)
- **k=10** (расширенный поиск)
- **k=20** (максимальный поиск)

#### Эксперимент 3: Query transformation
- **Включена** - преобразование вопросов в подробные запросы (приводило к нерелевантным результатам)
- **Отключена** - использование оригинального вопроса пользователя (лучшая точность)

### Какие параметры пробовали

| Параметр | Значение 1 | Значение 2 | Значение 3 | Значение 4 |
|----------|------------|------------|------------|------------|
| chunk_size | 500 | 600 | 800 | - |
| chunk_overlap | 50 | 80 | 100 | - |
| retriever_k | 3 | 7 | 10 | 20 |
| query_transform | enabled | disabled | - | - |

### Наблюдения и выводы: какая стратегия оказалась лучше для банковских документов

**Лучшая стратегия для банковских документов:**

1. **chunk_size=800, chunk_overlap=100** - банковские документы содержат длинные абзацы с подробной информацией, поэтому большие чанки лучше сохраняют контекст

2. **retriever_k=20** - максимальный охват поиска обеспечивает нахождение релевантных документов даже при неидеальном similarity matching

3. **Query transformation отключена** - использование оригинального вопроса пользователя дает более точные результаты, чем преобразование в подробные запросы

**Ключевые выводы:**
- Для документов с длинными текстовыми блоками (банковские документы) лучше использовать большие чанки
- Retrieval с высоким k компенсирует возможные проблемы с similarity search
- Query transformation может ухудшать качество поиска для точных вопросов

## Работа с JSON датасетом

### Как реализовали загрузку JSON

Изначально использовался `JSONLoader` из LangChain с `jq_schema`, но он не корректно обрабатывал структуру JSON файла. Была реализована кастомная функция `load_json_documents()`:

```python
def load_json_documents(json_file_path: str) -> list:
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    documents = []
    for item in data:
        if 'full_text' in item:
            doc = Document(
                page_content=item['full_text'],
                metadata={
                    'source': item.get('url', 'json'),
                    'category': item.get('category', 'unknown'),
                    'question': item.get('question', ''),
                    'type': item.get('type', 'qa')
                }
            )
            documents.append(doc)
    return documents
```

**Особенности реализации:**
- Ручная загрузка JSON без внешних зависимостей
- Создание Document объектов с полными метаданными
- Поддержка всех полей из JSON структуры
- Обработка ошибок и пустых значений

### Скриншот работы с вопросами про карты

![Скриншот работы с вопросами про карты](screenshots/cards_questions_demo.png)

*Примечание: Скриншот демонстрирует работу бота с вопросами о банковских картах из JSON датасета*

## Сравнение моделей эмбеддингов

### Какие модели эмбеддингов тестировали

В проекте тестировались две основные платформы эмбеддингов:

#### Fireworks AI
- **Модель**: `accounts/fireworks/models/qwen3-embedding-8b`
- **API**: `https://api.fireworks.ai/inference/v1`
- **Особенности**: Специализированная модель для эмбеддингов, оптимизированная для качества

#### OpenRouter/OpenAI (тестировалось)
- **Модель**: `text-embedding-3-large`
- **API**: `https://openrouter.ai/api/v1`
- **Особенности**: Классическая модель OpenAI, широко используемая

### Таблица сравнения качества ответов

| Критерий | Fireworks | OpenAI | Вывод |
|----------|-----------|--------|-------|
| **Точность поиска** | Высокая | Средняя | Fireworks лучше находит релевантные документы |
| **Качество эмбеддингов** | Отличное | Хорошее | Fireworks дает более точные векторы |
| **Скорость работы** | Быстрая | Средняя | Fireworks быстрее обрабатывает запросы |
| **Поддержка русского** | Отличная | Хорошая | Fireworks лучше работает с русским языком |
| **Стоимость** | Экономичная | Дорогая | Fireworks более доступен |
| **Стабильность** | Высокая | Высокая | Одинаково стабильны |

### Выводы: какая модель эмбеддингов лучше для русского языка

**Fireworks AI (`qwen3-embedding-8b`) оказалась значительно лучше для русского языка по следующим причинам:**

1. **Лучшее понимание русского контекста** - модель лучше распознает семантику русских текстов
2. **Высокая точность similarity search** - находит более релевантные документы для пользовательских вопросов
3. **Оптимизация под длинные тексты** - банковские документы содержат много терминов и длинных конструкций
4. **Лучшая производительность** - быстрее и дешевле при сохранении качества
5. **Специализация на эмбеддингах** - модель создана специально для задач векторного поиска

**Рекомендация:** Для проектов на русском языке с документами средней сложности Fireworks предоставляет оптимальное соотношение цена/качество.

---

*Отчет составлен на основе выполненной работы в проекте RAG-ассистент Сбербанка*  
*Дата выполнения: 16 ноября 2025 года*
